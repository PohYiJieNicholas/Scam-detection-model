{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, RobertaTokenizer, DistilBertTokenizer\n",
    "from transformers import BertForSequenceClassification, RobertaForSequenceClassification, DistilBertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the dataset is in CSV format and the path is \"path/to/your/ScamDataset.csv\"\n",
    "dataset_path = 'ScamDataset'  # Change to your file path\n",
    "\n",
    "\n",
    "# Preprocess messages\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('ScamDataset.csv', delimiter=',', names=['message', 'Label'])\n",
    "\n",
    "\n",
    "# Displaying the shape of the dataset before removing duplicates\n",
    "original_shape = data.shape\n",
    "\n",
    "# Removing duplicate rows\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Shape after removing duplicates\n",
    "new_shape = data.shape\n",
    "\n",
    "original_shape, new_shape\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stemmed = [stemmer.stem(word) for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(stemmed)\n",
    "\n",
    "data['processed_message'] = data['message'].apply(preprocess)\n",
    "data['processed_message']\n",
    "\n",
    "\n",
    "data['Label'] = data['Label'].map({'normal': 0, 'fraud': 1})\n",
    "\n",
    "texts = data['processed_message'].tolist()\n",
    "labels = data['Label'].tolist()\n",
    "# Split the dataset\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScamDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=128)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(int(self.labels[idx]))\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = (predictions == labels).mean()\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "# Define function for training and evaluation\n",
    "def train_and_evaluate(model_name):\n",
    "    print(f\"Training and evaluating {model_name}...\")\n",
    "    if model_name == 'bert':\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    elif model_name == 'roberta':\n",
    "        tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "        model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
    "    elif model_name == 'distilbert':\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "   \n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Model not supported\")\n",
    "\n",
    "    train_dataset = ScamDataset(train_texts, train_labels, tokenizer)\n",
    "    val_dataset = ScamDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',          \n",
    "        learning_rate = 1e-4,\n",
    "        per_device_train_batch_size = 8,\n",
    "        per_device_eval_batch_size = 8,\n",
    "        num_train_epochs = 2,\n",
    "        weight_decay = 0.01,\n",
    "        evaluation_strategy = 'epoch',\n",
    "        save_strategy = 'epoch',\n",
    "        load_best_model_at_end = True \n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,                         \n",
    "        args=training_args,                  \n",
    "        train_dataset=train_dataset,         \n",
    "        eval_dataset=val_dataset,  \n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    return trainer.evaluate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracies = {}\n",
    "model_name = 'bert'\n",
    "\n",
    "eval_results = train_and_evaluate(model_name)\n",
    "model_accuracies[model_name] = eval_results['eval_accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta'\n",
    "\n",
    "eval_results = train_and_evaluate(model_name)\n",
    "model_accuracies[model_name] = eval_results['eval_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilbert'\n",
    "\n",
    "eval_results = train_and_evaluate(model_name)\n",
    "model_accuracies[model_name] = eval_results['eval_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model Accuracies:')\n",
    "for model_name, accuracy in model_accuracies.items():\n",
    "    print(f\"{model_name}: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plotting the accuracies using a more distinct graph style\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a bar graph with distinct colors and edge color\n",
    "bars = plt.bar(model_accuracies.keys(), model_accuracies.values(), color=['blue', 'green', 'red'], edgecolor='black')\n",
    "\n",
    "# Add data labels above each bar for clarity\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.001, round(yval, 3), ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Model', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.title('Comparison of Model Accuracies on scam Detection', fontsize=16)\n",
    "plt.ylim(0.99, 1)  # Set y-axis limit to make differences more distinct\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
